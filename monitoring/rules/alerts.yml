# üè¢‚ö° Energy Optimizer Pro - Prometheus Alert Rules
# ================================================

groups:
  # =======================
  # üö® Critical System Alerts
  # =======================
  - name: system_critical
    rules:
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "üö® Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} has been down for more than 1 minute."
          runbook: "https://docs.energy-optimizer.com/runbooks/service-down"

      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "‚ö†Ô∏è High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% for more than 5 minutes on {{ $labels.instance }}"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "‚ö†Ô∏è High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% for more than 5 minutes on {{ $labels.instance }}"

      - alert: DiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "üö® Low disk space on {{ $labels.instance }}"
          description: "Disk usage is above 90% on {{ $labels.instance }}"

  # =======================
  # üåê Application Alerts
  # =======================
  - name: application_alerts
    rules:
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 3m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è High API latency detected"
          description: "95th percentile API latency is above 1 second for more than 3 minutes"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "üö® High API error rate"
          description: "API error rate is above 5% for more than 2 minutes"

      - alert: LowAPIThroughput
        expr: rate(http_requests_total[5m]) < 10
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è Low API throughput"
          description: "API request rate is below 10 requests/second for more than 10 minutes"

      - alert: DatabaseConnectionPoolExhausted
        expr: database_connections_active / database_connections_max > 0.9
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "üö® Database connection pool nearly exhausted"
          description: "Database connection pool usage is above 90%"

  # =======================
  # ‚ö° Energy-Specific Alerts
  # =======================
  - name: energy_alerts
    rules:
      - alert: EnergyConsumptionSpike
        expr: increase(building_energy_consumption_kwh[1h]) > building_energy_baseline_kwh * 1.5
        for: 15m
        labels:
          severity: warning
          team: energy
        annotations:
          summary: "‚ö†Ô∏è Energy consumption spike in building {{ $labels.building_id }}"
          description: "Energy consumption is 50% above baseline for building {{ $labels.building_name }}"

      - alert: BuildingEfficiencyDrop
        expr: building_efficiency_score < 0.6
        for: 30m
        labels:
          severity: warning
          team: energy
        annotations:
          summary: "‚ö†Ô∏è Building efficiency dropped below threshold"
          description: "Building {{ $labels.building_name }} efficiency is below 60%"

      - alert: OptimizationJobFailed
        expr: increase(ml_optimization_jobs_failed_total[1h]) > 3
        for: 5m
        labels:
          severity: warning
          team: ml
        annotations:
          summary: "‚ö†Ô∏è Multiple optimization jobs failed"
          description: "More than 3 optimization jobs failed in the last hour"

      - alert: PredictionAccuracyLow
        expr: ml_model_accuracy < 0.85
        for: 1h
        labels:
          severity: warning
          team: ml
        annotations:
          summary: "‚ö†Ô∏è ML model accuracy below threshold"
          description: "Model {{ $labels.model_name }} accuracy is below 85%"

  # =======================
  # üíæ Database Alerts
  # =======================
  - name: database_alerts
    rules:
      - alert: DatabaseDown
        expr: postgres_up == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "üö® PostgreSQL database is down"
          description: "PostgreSQL database has been down for more than 1 minute"

      - alert: SlowDatabaseQueries
        expr: histogram_quantile(0.95, rate(postgres_query_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è Slow database queries detected"
          description: "95th percentile query time is above 5 seconds"

      - alert: DatabaseConnectionsHigh
        expr: postgres_stat_activity_count > postgres_settings_max_connections * 0.8
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è High database connection usage"
          description: "Database connections are above 80% of maximum"

      - alert: DatabaseLockWait
        expr: postgres_stat_activity_max_tx_duration > 300
        for: 2m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è Long-running database transactions"
          description: "Database transactions running for more than 5 minutes"

  # =======================
  # üóÑÔ∏è Redis Cache Alerts
  # =======================
  - name: redis_alerts
    rules:
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "üö® Redis cache is down"
          description: "Redis cache has been down for more than 1 minute"

      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "‚ö†Ô∏è Redis memory usage high"
          description: "Redis memory usage is above 90%"

      - alert: RedisCacheMissRateHigh
        expr: rate(redis_keyspace_misses_total[5m]) / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m])) > 0.3
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è High Redis cache miss rate"
          description: "Redis cache miss rate is above 30% for more than 10 minutes"

  # =======================
  # üåê Frontend Alerts
  # =======================
  - name: frontend_alerts
    rules:
      - alert: FrontendDown
        expr: probe_success{job="frontend-health"} == 0
        for: 2m
        labels:
          severity: critical
          team: frontend
        annotations:
          summary: "üö® Frontend application is down"
          description: "Frontend health check has been failing for more than 2 minutes"

      - alert: HighJavaScriptErrors
        expr: rate(frontend_javascript_errors_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          team: frontend
        annotations:
          summary: "‚ö†Ô∏è High JavaScript error rate"
          description: "Frontend JavaScript error rate is above 10% for more than 5 minutes"

  # =======================
  # ü§ñ ML Model Alerts
  # =======================
  - name: ml_alerts
    rules:
      - alert: ModelTrainingStuck
        expr: time() - ml_model_last_training_timestamp > 86400
        for: 1h
        labels:
          severity: warning
          team: ml
        annotations:
          summary: "‚ö†Ô∏è ML model training overdue"
          description: "Model {{ $labels.model_name }} hasn't been retrained in over 24 hours"

      - alert: PredictionLatencyHigh
        expr: histogram_quantile(0.95, rate(ml_prediction_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          team: ml
        annotations:
          summary: "‚ö†Ô∏è High ML prediction latency"
          description: "95th percentile ML prediction time is above 1 second"

      - alert: ModelDriftDetected
        expr: ml_model_drift_score > 0.1
        for: 15m
        labels:
          severity: warning
          team: ml
        annotations:
          summary: "‚ö†Ô∏è ML model drift detected"
          description: "Model {{ $labels.model_name }} shows signs of drift (score: {{ $value }})"

  # =======================
  # ‚ö° Business Metrics Alerts
  # =======================
  - name: business_alerts
    rules:
      - alert: EnergyEfficiencyDegraded
        expr: avg_over_time(building_efficiency_score[24h]) < 0.7
        for: 2h
        labels:
          severity: warning
          team: energy
        annotations:
          summary: "‚ö†Ô∏è Building energy efficiency degraded"
          description: "Building {{ $labels.building_name }} efficiency is below 70% for 2+ hours"

      - alert: CostThresholdExceeded
        expr: building_daily_cost_eur > building_daily_cost_budget_eur * 1.2
        for: 1h
        labels:
          severity: warning
          team: finance
        annotations:
          summary: "‚ö†Ô∏è Daily energy cost budget exceeded"
          description: "Building {{ $labels.building_name }} exceeded daily cost budget by 20%"

      - alert: CarbonFootprintHigh
        expr: building_daily_carbon_kg > building_carbon_target_kg * 1.3
        for: 4h
        labels:
          severity: warning
          team: sustainability
        annotations:
          summary: "‚ö†Ô∏è Carbon footprint above target"
          description: "Building {{ $labels.building_name }} carbon footprint 30% above target"

  # =======================
  # üîÑ Data Pipeline Alerts
  # =======================
  - name: data_pipeline_alerts
    rules:
      - alert: DataIngestionDelayed
        expr: time() - data_last_ingestion_timestamp > 3600
        for: 30m
        labels:
          severity: warning
          team: data
        annotations:
          summary: "‚ö†Ô∏è Data ingestion delayed"
          description: "No new data ingested for building {{ $labels.building_id }} in over 1 hour"

      - alert: DataQualityIssue
        expr: data_quality_score < 0.8
        for: 15m
        labels:
          severity: warning
          team: data
        annotations:
          summary: "‚ö†Ô∏è Data quality issue detected"
          description: "Data quality score for {{ $labels.data_source }} is below 80%"

      - alert: DataStorageSpaceLow
        expr: data_storage_used_bytes / data_storage_total_bytes > 0.85
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "‚ö†Ô∏è Data storage space low"
          description: "Data storage usage is above 85%"

  # =======================
  # üå°Ô∏è Environmental Alerts
  # =======================
  - name: environmental_alerts
    rules:
      - alert: TemperatureAnomalyDetected
        expr: abs(building_temperature_celsius - building_temperature_setpoint_celsius) > 5
        for: 30m
        labels:
          severity: warning
          team: facilities
        annotations:
          summary: "‚ö†Ô∏è Temperature anomaly in building"
          description: "Temperature in {{ $labels.building_name }} deviates more than 5¬∞C from setpoint"

      - alert: HumidityOutOfRange
        expr: building_humidity_percent < 30 or building_humidity_percent > 70
        for: 45m
        labels:
          severity: info
          team: facilities
        annotations:
          summary: "‚ÑπÔ∏è Humidity out of optimal range"
          description: "Humidity in {{ $labels.building_name }} is outside optimal range (30-70%)"

  # =======================
  # üîê Security Alerts
  # =======================
  - name: security_alerts
    rules:
      - alert: UnusualAPIActivity
        expr: rate(http_requests_total[5m]) > 1000
        for: 2m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "‚ö†Ô∏è Unusual API activity detected"
          description: "API request rate is unusually high ({{ $value }} req/sec)"

      - alert: FailedAuthenticationAttempts
        expr: rate(auth_failed_attempts_total[5m]) > 10
        for: 3m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "‚ö†Ô∏è High failed authentication rate"
          description: "Failed authentication attempts: {{ $value }} per second"

      - alert: SecurityScanDetected
        expr: rate(http_requests_total{status_code="404"}[1m]) > 50
        for: 2m
        labels:
          severity: info
          team: security
        annotations:
          summary: "‚ÑπÔ∏è Possible security scan detected"
          description: "High rate of 404 responses may indicate security scanning"

  # =======================
  # üìä Performance Alerts
  # =======================
  - name: performance_alerts
    rules:
      - alert: ResponseTimeSLOViolation
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è SLO violation: High response times"
          description: "95th percentile response time is above 2 seconds"

      - alert: WebSocketConnectionsHigh
        expr: websocket_connections_active > 100
        for: 10m
        labels:
          severity: info
          team: backend
        annotations:
          summary: "‚ÑπÔ∏è High WebSocket connection count"
          description: "Active WebSocket connections: {{ $value }}"

      - alert: QueueBacklogHigh
        expr: celery_task_queue_length > 100
        for: 15m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "‚ö†Ô∏è High task queue backlog"
          description: "Celery task queue has {{ $value }} pending tasks"

  # =======================
  # üè¢ Building-Specific Alerts
  # =======================
  - name: building_alerts
    rules:
      - alert: BuildingOffline
        expr: building_last_data_timestamp < time() - 1800
        for: 5m
        labels:
          severity: critical
          team: facilities
        annotations:
          summary: "üö® Building data stream offline"
          description: "No data received from {{ $labels.building_name }} for over 30 minutes"

      - alert: EnergyBaselineDeviation
        expr: abs((building_current_consumption - building_baseline_consumption) / building_baseline_consumption) > 0.3
        for: 1h
        labels:
          severity: warning
          team: energy
        annotations:
          summary: "‚ö†Ô∏è Energy consumption deviates from baseline"
          description: "{{ $labels.building_name }} consumption deviates more than 30% from baseline"

      - alert: PeakDemandExceeded
        expr: building_current_demand_kw > building_peak_demand_limit_kw
        for: 5m
        labels:
          severity: critical
          team: energy
        annotations:
          summary: "üö® Peak demand limit exceeded"
          description: "{{ $labels.building_name }} demand ({{ $value }}kW) exceeds limit"

  # =======================
  # üîÑ Maintenance Alerts
  # =======================
  - name: maintenance_alerts
    rules:
      - alert: EquipmentMaintenanceDue
        expr: equipment_maintenance_due_days < 7
        for: 1h
        labels:
          severity: info
          team: facilities
        annotations:
          summary: "‚ÑπÔ∏è Equipment maintenance due soon"
          description: "{{ $labels.equipment_name }} in {{ $labels.building_name }} needs maintenance in {{ $value }} days"

      - alert: EquipmentPerformanceDegraded
        expr: equipment_efficiency_score < 0.7
        for: 2h
        labels:
          severity: warning
          team: facilities
        annotations:
          summary: "‚ö†Ô∏è Equipment performance degraded"
          description: "{{ $labels.equipment_name }} efficiency below 70%"

  # =======================
  # üí∞ Cost Management Alerts
  # =======================
  - name: cost_alerts
    rules:
      - alert: MonthlyBudgetExceeded
        expr: building_monthly_cost_eur > building_monthly_budget_eur
        for: 1h
        labels:
          severity: warning
          team: finance
        annotations:
          summary: "‚ö†Ô∏è Monthly energy budget exceeded"
          description: "{{ $labels.building_name }} exceeded monthly budget of ‚Ç¨{{ $labels.building_monthly_budget_eur }}"

      - alert: EnergyPriceSpike
        expr: current_energy_price_eur_per_kwh > historical_avg_price_eur_per_kwh * 1.4
        for: 30m
        labels:
          severity: info
          team: procurement
        annotations:
          summary: "‚ÑπÔ∏è Energy price spike detected"
          description: "Current energy price (‚Ç¨{{ $value }}/kWh) is 40% above historical average"

  # =======================
  # üå± Sustainability Alerts
  # =======================
  - name: sustainability_alerts
    rules:
      - alert: CarbonEmissionsHigh
        expr: building_daily_carbon_emissions_kg > building_carbon_target_kg * 1.2
        for: 4h
        labels:
          severity: warning
          team: sustainability
        annotations:
          summary: "‚ö†Ô∏è High carbon emissions"
          description: "{{ $labels.building_name }} emissions 20% above sustainability target"

      - alert: RenewableEnergyLow
        expr: building_renewable_energy_percent < 30
        for: 24h
        labels:
          severity: info
          team: sustainability
        annotations:
          summary: "‚ÑπÔ∏è Low renewable energy usage"
          description: "{{ $labels.building_name }} renewable energy usage below 30%"

  # =======================
  # üìà Trend-Based Alerts
  # =======================
  - name: trend_alerts
    rules:
      - alert: EnergyConsumptionTrendIncreasing
        expr: deriv(building_energy_consumption_kwh[7d]) > building_baseline_consumption_kwh * 0.02
        for: 3d
        labels:
          severity: info
          team: energy
        annotations:
          summary: "‚ÑπÔ∏è Increasing energy consumption trend"
          description: "{{ $labels.building_name }} shows increasing consumption trend over 7 days"

      - alert: EfficiencyTrendDecreasing  
        expr: deriv(building_efficiency_score[7d]) < -0.01
        for: 3d
        labels:
          severity: warning
          team: energy
        annotations:
          summary: "‚ö†Ô∏è Decreasing efficiency trend"
          description: "{{ $labels.building_name }} efficiency trending downward over 7 days"

# Alert notification routing (requires Alertmanager)
# This configuration would go in alertmanager.yml:
#
# route:
#   group_by: ['alertname', 'severity']
#   group_wait: 30s
#   group_interval: 5m
#   repeat_interval: 12h
#   receiver: 'default'
#   routes:
#     - match:
#         severity: critical
#       receiver: 'critical-alerts'
#     - match:
#         team: ml
#       receiver: 'ml-team'
#
# receivers:
#   - name: 'default'
#     slack_configs:
#       - api_url: 'YOUR_SLACK_WEBHOOK_URL'
#         channel: '#energy-optimizer-alerts'
#
#   - name: 'critical-alerts'
#     slack_configs:
#       - api_url: 'YOUR_CRITICAL_SLACK_WEBHOOK_URL'
#         channel: '#critical-alerts'
#     email_configs:
#       - to: 'oncall@energy-optimizer.com'
#         subject: 'üö® Critical Alert: {{ .GroupLabels.alertname }}'
